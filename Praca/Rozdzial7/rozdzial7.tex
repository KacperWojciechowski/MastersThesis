\chapter{Zestawienie zbiorcze i podsumowanie}

\section{Oferowane funkcjonalności}

Omówione w ramach niniejszej pracy biblioteki różnią się typem i ilością oferowanych funkcjonalności. Tabela \ref{fun:sum} zbiorczo podsumowuje poszczególne omówione w poprzednich rozdziałach aspekty.

\begin{longtable}{c | c | c | c}
	\centering
	\multirow{2}{*}{\makecell{Funkcjonalność}} & \multicolumn{3}{c}{Biblioteka} \\
	\cline{2-4}
	 &  Shogun & Shark-ML & Dlib \\
	\hline
	\makecell{Odczyt \\ danych} & \makecell{std::vector, \\ wsparcie dla \\ formatu CSV} & \makecell{surowe \\ tablice, \\ wsparcie dla \\ formatu CSV, \\ wsparcie \\ dla HTTP} & \makecell{std::vector, \\ wsparcie dla \\ formatu CSV} \\
	\hline
	{Normalizacja} & min-max & \makecell{przedział \\ jednostkowy, \\ jednostkowa \\ wariancja, \\ zerowa \\ średnia i \\ wybrana \\ wariancja} & standaryzacja \\
	\hline
	\makecell{Redukcja \\ wymiarowości} & \makecell{PCA, Kernel PCA, \\ MDS, IsoMap, \\ ICA, Factor analysis, \\t-SNE} & \makecell{PCA, Liniowa \\ analiza \\ dyskryminacyjna} & \makecell{PCA, Liniowa \\ analiza \\ dyskryminacyjna, \\ Mapowanie \\ Sammona} \\
	\hline
	\makecell{Regularyzacja} & \makecell{L1 i L2 \\ automatyczna} & \makecell{L1 i L2} & L2 \\
	\hline
	\makecell{Regresja \\ liniowa} & Tak & Tak & Tak \\
	\hline
	\makecell{Regresja \\ logistyczna} & Tak & Tak & Nie \\
	\hline
	\makecell{Maszyna \\ wektorów \\ nośnych} & Tak & Tak & Tak \\
	\hline
	\makecell{Algorytm \\ K-najbliższych \\ sąsiadów} & Tak & Tak & Nie \\
	\hline
	\makecell{Algorytm \\ zbiorowy} & \makecell{Wzmacnianie \\ gradientu, \\ losowy las} & \makecell{Losowy \\ las} & Nie \\
	\hline
	\makecell{Sieć \\ neuronowa} & Tak & Tak & Tak \\
	\hline
	\makecell{Brzegowa \\ regresja \\ jądra} & Nie & Nie & Tak \\
	\hline
	\makecell{Błąd \\ średniokwadratowy} & Tak & Tak & Nie \\
	\hline
	\makecell{Średni \\ błąd \\ absolutny} & Tak & Tak & Nie \\
	\hline
	\makecell{Błąd typu \\ zero-one} & Nie & Tak & Nie \\
	\hline
	\makecell{Błąd \\ dyskretny} & Nie & Tak & Nie \\
	\hline
	\makecell{Entropia \\ krzyżowa} & Nie & Tak & Nie \\
	\hline
	\makecell{Błąd typu \\ hinge} & Nie & Tak & Nie \\
	\hline
	\makecell{Średnio-\\kwadratowy \\ błąd typu \\ hinge} & Nie & Tak & Nie\\
	\hline
	\makecell{Błąd typu \\ hinge epsilon} & Nie & Tak & Nie\\
	\hline
	\makecell{Średnio-\\kwadratowy \\ błąd typu \\ hinge epsilon} & Nie & Tak & Nie\\
	\hline
	\makecell{Funkcja \\ straty \\ Hubera} & Nie & Tak & Nie\\
	\hline
	\makecell{Funkcja \\ straty \\ Tukeya} & Nie & Tak & Nie\\
	\hline
	\makecell{Logarytmiczna \\ funkcja \\ straty} & Tak & Nie & Nie\\
	\hline
	\makecell{Metryka $R^2$} & Tak & Tak & Nie\\
	\hline
	\makecell{Dokładność} & Tak & Nie & Tak \\
	\hline
	\makecell{Pole pod \\ wykresem \\ ROC} & Tak & Tak & Tak* \\
	\hline
	\makecell{Sprawdzian \\ krzyżowy \\ k-krotny} & Tak & Tak & Tak \\
	\caption{Zbiorcze porównanie funkcjonalności bibliotek}
	\label{fun:sum}
\end{longtable} 

* - konieczność przeliczenia pola na podstawie uzyskanych punktów pomiarowych wykresu funkcji.

Analizując dane zebrane w tabeli \ref{fun:sum} zauważyć można, że biblioteki Shogun oraz Shark-ML są bardzo zbliżone do siebie typem i ilością dostępnych metod uczenia maszynowego, jednak Shark-ML posiada więcej rodzajów błędów możliwych do wykorzystania jako funkcje strat, pozwalając na większą swobodę względem dostosowywania procesu uczenia. Najmniejszą ilością funkcjonalności charakteryzuje się biblioteka Dlib, posiadająca jedynie podzbiór algorytmów dostępnych w innych projektach. Ponadto, posiada ona bardzo ubogie możliwości analizy sprawności modeli, wymagając od użytkownika napisania własnych procedur przetwarzania uzyskanych danych, jak np. procedura obliczania pola pod wykresem krzywej charakterystycznej odbiornika.

\section{Porównanie wyników dla zadanych przykładów}
\section{Wymagany nakład pracy i jakość źródeł}

W procesie pracy z poszczególnymi bibliotekami zauważono, że najmniejszą ilością potrzebnego wkładu pracy charakteryzowała się biblioteka Shark-ML. Wynika to z bardzo przyjaznej dla użytkownika składni, oraz dokładnej dokumentacji dostępnej na stronie internetowej projektu, wraz z przykładami wykorzystania poszczególnych metod. Biblioteka także bez jakichkolwiek problemów została zbudowana i zainstalowana na systemie operacyjnym Ubuntu 22.04 w środowisku WSL, pozwalając bardzo szybko przejść do docelowej pracy.

Drugą biblioteką pod względem koniecznego wkładu czasu okazał się zestaw narzędziowy Dlib. Posiada on stronę projektu z wylistowanymi klasami oraz funkcjami dostępnymi w bibliotece, jednak opis działania poszczególnych metod jest bardzo pobieżny, oraz brakuje dostępnych przykładów. Składnia biblioteki może stanowić wyzwanie dla użytkownika, gdyż nie zawsze jest oczywista, i momentami utrudnia analizę realizowanych przez program operacji.

Jako najbardziej wymagającą bibliotekę uznano Shogun. W chwili pisania niniejszej pracy, zarówno oficjalne repozytorium projektu jak i repozytorium dystrybucji dla systemu operacyjnego Ubuntu okazało się być niekompletne. Uniemożliwiło to zainstalowanie biblioteki za pomocą wbudowanego managera pakietów oraz zbudowanie jej ze względu na nienaprawione zależności do przeniesionych repozytoriów stron trzecich. Mimo przyjaźniejszej składni niż w przypadku Dlib, wspomniany wcześniej mankament sprawia, że w celu pobrania biblioteki konieczne okazało się zainstalowanie specjalnego managera pakietów \textit{nix} posiadającego starszą wersję projektu Shogun dostępną na swoim repozytorium. Z racji braku dostępnej online dokumentacji projektu Shogun oraz faktu, że generowane przykłady nie odnoszą się do API biblioteki lecz używają jej w kompletnie odrębny, nienaturalny dla projektu sposób, ustalenie funkcjonalności oraz sposobu realizacji poszczególnych zadań uczenia maszynowego musiało zostać oparte praktycznie wyłącznie o materiały dostępne w formie książkowej. Znacznie utrudnia i wydłuża to proces zastosowania biblioteki do jakiegokolwiek projektu.