\chapter{Biblioteka TensorFlow}

\section{Wprowadzenie}

Tnesorflow to darmowa biblioteka do uczenia maszynowego typu \textit{open-source} stworzona przez Google. Oferuje ona możliwość przeprowadzenia płytkiego oraz głębokiego uczenia maszynowego, z wykorzystaniem własnych lub gotowych zestawów danych. Pozwala ona także na użycie pretrenowanych modeli jako rozwiązanie docelowe lub część składowa własnego modelu. Stanowi ona jedną z najpopularniejszych bibliotek ML, w szczególności wśród osób dopiero rozpoczynające swoje doświadczenia z tą gałęzią informatyki.

Jak podano na stronie domowej biblioteki Tensorflow\cite{tf}, deklaruje ona bycie odpowiednią zarówno do przeprowadzania badań, jak i do wykorzystania w zastosowaniach przemysłowych. W momencie pisania niniejszej pracy, najnowszą dostępną wersją jest Tensorflow 2.11.

\section{Metody wdrożenia modeli}

Biblioteka umożliwia następujące metody wdrożenia modeli dla języka C++ \cite{protobuf}\cite{deploy3}\cite{tflite}:

\begin{itemize}
	\item API TensorFlow w języku C++
	\item Środowisko wykonawcze ONNX
	\item Zestaw narzędzi TensorFlow Lite
	\item Za pomocą Protobuf
\end{itemize}

\subsection{API w języku C++}

Z racji bycia napisanym w języku C++, biblioteka TensorFlow oferuje wsparcie do tworzenia, ternowania, i wdrażania modeli uczenia maszynowego w tym języku, poprzez udostępnienie użytkownikom interfejsu programowania aplikacji (ang. \textit{Application Programming Interface, API}). Udostępnia ono operacje pozwalające manipulacje tensorami, wykonywanie operacji matematycznych na tensorach i ich elementach, budowę modelu w postaci grafu obliczeniowego, oraz jego uruchomienia wykorzystując różne metody obliczeniowe, np. Adagrad oraz metodę spadku gradientowego \cite{tfcpp}. Zastosowanie tego API pozwala na utworzenie i pracę z modelem bezpośrednio w aplikacji pisanej w języku C++.

\cppcode{Rozdzial4/helloworldgraph.cpp}{Przykład utworzenia grafu obliczeniowego w TensorFlow realizującego konkatenację ciągów znakowych \cite{tfhelloworld}}

\subsection{Środowisko wykonawcze ONNX}

\textit{Open Neural Networks Exchange, (ONNX)} to środowisko mające na celu standaryzację reprezentacji modeli uczenia maszynowego, autorstwa firmy Microsoft \cite{deploy3}. Pozwala ono na uniezależnienie modelu na etapie wdrożenia od biblioteki i języka w którym został stworzony, pozwalając na ich użycie przy pomocy pojedynczego mechianizmu. Wykorzystanie tej metody wdrażania modeli polega na przygotowaniu ich za pomocą API języka okraz eksport do struktury akceptowanej przez środowisko wykonawcze ONNX.

\subsection{Zestaw narzędzi TensorFlow Lite}

Stanowi zbiór narzędzi (ang. \textit{toolbox}) umożliwiających uruchomienie przygotowanych modeli na platformach mobilnych oraz urządzeniach brzegowych (takich jak moduły IoT, lub ogólnie rozumiane systemy mokroprocesorowe). Pozwala on dodatkowo m.in. na wykorzystanie akceleracji sprzętowej oraz optymalizacji modelu. Przygotowywanie modeli do uruchomienia za pomocą tej metody na wybranej platformie składa się m.in. z przygotowania modelu z użyciem biblioteki TensorFlow Lite Model Maker, wykorzystania jednego z gotowych, pretrenowanych modeli, lub konwersji modelu TensorFlow z formatu protobuf \cite{tflite}.

\subsection{Za pomocą Protobuf}

Utworzony w bibliotece TensorFlow model jest zapisywany do formatu wykorzystywanego przez mechanizm Protocol Buffers autorstwa Google, zwanego potocznie \textit{Protobuf}. Pozwala on na przechowywanie grafu obliczeniowego modelu w notacji niezależnej od języków programowania, z której następnie narzędzie Protobuf umożliwia wygenerowanie odpowiednich klas i struktur danych dla wybranego języka, jak np. C++ czy Python \cite{protobuf2}. Pliki Protobuf mogą mieć formę tekstową, która ułatwia edycję i analizę człowiekowi, lub formę binarną, pozwalającą na znaczne zaoszczędzenie miejsca w przypadku przechowywania danych numerycznych, jak np. wagi połączeń sieci. 

\cppcode{Rozdzial4/cppconstructor.cpp}{Konstruktor klasy \textit{Model} odczytujący strukturę modelu z pliku Protobuf \cite{input_tf}}

\section{Formaty źródeł danych}

W języku C++ biblioteka TensorFlow wymaga podania danych w postaci obiektów klasy szablonowej \textit{std::vector} z biblioteki STL języka \cite{input_tf}, lub za pomocą własnych klas, np. \textit{FeedDict}, jednak nie określa w jaki sposób muszą te dane być przechowywane. W związku z tym, możliwe jest wykorzystanie dowolnego formatu przechowywania danych do uczenia, pod warunkiem zapewnienia mechanizmu ich parsowania. Typ przechowywany przez obiekty std::vector zależny jest od ilości regresorów, i może przyjmować postać typu prostego lub złożonego. Dane powinny być rozgraniczone przed procesem uczenia na dwa wektory, z których jeden przechowuje dane uczące, natomiast drugi dane walidacyjne.

\cppcode{Rozdzial4/tfruntrainingstep.cpp}{Przykładowa funkcja realizująca krok uczenia \cite{input_tf}}

\section{Metody przetwarzania i eksploracji danych}

API biblioteki TensorFlow dla języka C++ oferuje wiele operacji możliwych do wykonania na danych wykorzystywanych do uczenia. Operacje te można podzielić na manipulujące strukturą zapisanych danych (pozwalające na przetworzenie tensorów lub optymalizację pracy z danymi), oraz manipulujące wartościami regresorów (jak np. operacje matematyczne). Poniżej wymieniono wybrane, szczególnie istotne funkcjonalności przetwarzania i eksploracji danych, wyszczególnione w dokumentacji \cite{tfcpp}:

\subsection{Operacje strukturalne}

Są to operacje mające na celu modyfikację struktury w jakich przechowywane są dane. Biblioteka oferuje szereg funkcjonalności mających na celu reformatowanie danych w celu optymalizacji wykonywania na nich obliczeń\cite{tfcpp}. Należą do nich:

\begin{itemize}
	\item \textbf{bitcast} - zmiana typu tensora bez kopiowania danych;
	\item \textbf{dekwantyzacja} - zamiana na typ zmiennoprzecinkowy z formatu stałoprzecinkowego lub całkowitoliczbowej notacji wykładniczej;
	\item \textbf{udawana kwantyzacja} - wykorzystywana do przygotowania danych aby móc z nich obliczyć gradient (dostępne jest kilka rodzajów udawanej kwantyzacji);
	\item \textbf{padding} - otoczenie wartości tensora nadmiarowymi wartościami w celu dostosowania wymiarów (możliwe uzupełnienie np. zerami, lub wartościami lustrzanymi);
	\item \textbf{stacking} - złącza N tensorów R-wymiarowych w jeden tensor R+1-wymiarowy;
	\item \textbf{dynamic stitching i partitioning} - złączanie danych z wielu tensorów w jeden lub rozdzielanie z jednego na wiele;
	\item \textbf{serializacja} - konwersja tensora na serializowany format dla Protobuf.
\end{itemize}

\subsection{Eksploracja danych}

W dokumentacji API TensorFlow dla C++ możliwe jest znalezienie wielu operacji pozwalających manipulować wartościami danych w celu wyliczenia pewnych cech, lub dokonania obliczeń potrzebnych w trakcie procesu uczenia\cite{tfcpp}. Do najistotniejszych z nich należą:

\begin{itemize}
	\item wyliczanie odcisku palca danych (ang. \textit{fingerprint});
	\item weryfikacja czy dane zawierają wartości NaN lub inf;
	\item wyodrębnienie fragmentów obrazów do warstwy ,,depth'';
	\item obliczenie gradientu z danych po udawanej kwantyzacji;
	\item obliczanie rzadkiego (ang. \textit{sparse}) gradientu dla danego akumulatora;
	\item obliczenie odwrotnej permutacji tensora;
	\item normalizacja za pomocą kwantyzacji;
	\item wybór kandydatów do ewaluacji funkcji wyjściowych (ang. \textit{candidate sampling});
	\item dostosowywanie nasycenia, kontrastu i kolorystyki obrazów;
	\item dekodowanie obrazów z różnych formatów (np. gif, bmp, jpg, bmp);
	\item dekodowanie danych z różnych źródeł (np. csv, json);
	\item generowanie ramek (ang. \textit{bounding box});
	\item zmiana rozmiaru obrazów;
	\item rekodowanie obrazu z kolorystyki RGB na HSV;
	\item zachłanna selekcja ramek;
	\item różnorodne operacje matematyczne;
	\item pooling i konwoolucję;
	\item normalizację z pomocą gradientów;
	\item różnorodne funkcje aktywacji i straty;
	\item operacje na ciągach znakowych;
	\item algorytmy treningowe, jak np. Adagrad, Adadelta, centered RMSProp.
	
\end{itemize}

\subsection{Sterowanie przepływem obliczeń}

Oprócz wymienionych wcześniej poleceń optymalizujących lub przetwarzających dane, biblioteka TensorFlow posiada szereg operacji zarządzających przepływem danych w grafie obliczeniowym reprezentującym model. Należą do nich:

\begin{itemize}
	\item operacje na zakumulowanych gradientach;
	\item ustawianie barier;
	\item operacje na mapach, kolejkach i tablicach tensorów.
	
\end{itemize}

\section{Modele uczenia maszynowego}

Biblioteka TensorFlow z racji dostarczania operacji na tensorach i realizacji przetwarzania za pomocą grafu obliczeniowego, wspiera szereg modeli zarówno płytkiego jak i głębokiego uczenia maszynowego. Należą do nich \cite{tfcookbook}:

\begin{itemize}
	\item regresja liniowa;
	\item regresja logistyczna;
	\item regresja Deminga;
	\item regresja grzbietowa i lasso;
	\item maszyna wektorów nośnych;
	\item jednokierunkowa sieć neuronowa (ang. \textit{feedforward neural network});
	\item splotowa sieć neuronowa;
	\item rekurencyjna sieć neuronowa;
	\item autoenkodery;
	\item wzmocnione uczenie maszynowe;
\end{itemize}

Powyższe modele mogą zostać wykorzystane do rozwiązywania wielu problemów, w tym także o charakterystyce liniowej czy klasyfikacji. Poniższe fragmenty omawiają sposób implementacji poszczególnych modeli, oraz przedstawiają praktyczne przykłady dla wybranych z nich.

\subsection{Regresja liniowa}

Regresja liniowa przy wykorzystaniu API TensorFlow wykonywana jest poprzez metodę macierzy odwrotnej. Problem określony jest wzorem:

\begin{equation}
	Ax = b
\end{equation}

gdzie A odpowiada za macierz wartości regresorów, x za wektor współczynników poszczególnych zmiennych, a b stanowi wektor wartości oczekiwanych. Rozwiązanie w postaci ogólnej określić można wzorem:

\begin{equation}
	x = (A^TA)^{-1}A^Tb
\end{equation}

Operacje te wykonać można wykorzystując transpozycję oraz iloczyn tensorów, dostępny w sekcji matematycznej API TensorFlow. Pozostałe rodzaje regresji przedstawione w dalszych sekcjach, korzystają z wyżej opisanego mechanizmu.

\subsection{Regresja logistyczna}

Implementacja regresji logistycznej wykorzystuje proces regresji liniowej, jednak dokonuje na wyjściu normalizacji przewidywanego wyniku z użyciem funkcji sigmoidalnej, otrzymując prawdopodobieństwo przynależności. Obserwacja jest uznawana za należącą do sprawdzanej klasy jeżeli znormalizowana wartość przekroczy pewną zadaną wartość progową.

Implementację rozpoczęto od przygotowania mechanizmu parsowania pliku zawierającego dane eksperymentalne do postaci macierzy regresorów i wektora diagnozy. Wykorzystano w tym celu możliwość parsowania pliku CSV z dostępnego API biblioteki.

\subsection{Regresja Deminga}

Polega ona na minimalizowaniu całkowitego dystansu pomiędzy punktami pomiarowymi a uzyskaną prostą, zamiast minimalizacji dystansu pionowego. W celu jej uzyskania należy wykorzystać mechanizm regresji liniowej, modyfikując funkcję straty, w celu minimalizacji następującego wzoru:

\begin{equation}
	d = \frac{y_0 - (ax_0 + b)}{\sqrt{m^2 + 1}}
\end{equation}

gdzie (x\texttt{\char`_}0, y\texttt{\char`_}0) oznaczają punkt pomiarowy, a prosta uzyskiwana w wyniku regresji dana jest wzorem y = ax + b. Powyższy wzór ma zastosowanie dla pomiarów w przestrzeni dwuwymiarowej (jeden regresor i jedna wartość odpowiedzi). W przypadku większej liczby regresorów należy zastosować metodę operatą o ilocznym skalarny wektorów N+1 wymiarowych, gdzie N oznacza ilość regresorów, za pomocą 3 punktów (punktu dla którego liczymy odległość, czyli obserwacji [punkt P], oraz dwóch punktów leżących na prostej uzyskanej w wyniku regresji [punkty A i B]). Metoda ta przedstawiona jest następującymi wzorami \cite{engineeringstackdistance}:

\begin{equation}
	\overrightarrow{pa} = P - A
\end{equation}

\begin{equation}
	\overrightarrow{ba} = B - A
\end{equation}

\begin{equation}
	t = (\overrightarrow{pa} \cdot \overrightarrow{ba}) / (\overrightarrow{ba} \cdot \overrightarrow{ba})
\end{equation}

\begin{equation}
	d = \lvert \overrightarrow{pa} - t * \overrightarrow{ba} \rvert
\end{equation}

Wzór 4.7 przedstawia wynikową formułę obliczania odległości, która musi być minimalizowana w ramach funkcji straty.

\section{Metody analizy modeli}
\section{Dostępność dokumentacji i źródeł wiedzy}

Niestety biblioteka TensorFlow posiada bardzo ograniczone zasoby umożliwiające pisanie z jej użyciem programów w języku C++. Dokumentacja okazuje się bardzo ograniczona i niekompletna. Dodatkowo niewielka liczba osób korzysta z tej biblioteki w języku C++, przez co ciężko znaleźć artykuły lub publikacje które prezentowałyby przykłady kodu źródłowego lub omawiały sposób pracy z udostępnionym API. Wiele dostępnych w API poleceń jak np. Placeholder, nie znalazło się w oficjalnej liście dostępnych funkcji i klas.