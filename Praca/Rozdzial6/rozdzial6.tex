\chapter{Dlib}

\section{Introduction}

Dlib is a machine learning library written in modern C++, made for industrial and scientific purposes\cite{Dlib09}. Similarly to previously discussed libraries, it has an open source using \textit{Boost Software License}\cite{dlib:license}. Among the fields in which this library is utilized are robotics, embedded systems, telecommunication and high performance software. The project's code is equipped with unit tests, which allows for easier maintaining the quality of provided solutions. Interesting is the fact, that Dlib is not only a library, but also a toolbox, which provides functionalities beyond the scope of machine learning.

\section{Data formats}

Dlib uses C++ standard STL library for representing vectors within its code. Additionally, there is a possibility of initializing them using the comma operator, and wrapping a raw array. This means, that similarly to the Shogun library, data can be stored and passed to the program in any way that puts them inside eg. a raw array, to later process it into form accepted by the library. The raw array method works also with the STL containers which allow access to their internal buffers in the array form via the \textit{data()} method. Similarly to previous solutions, Dlib also provides the CSV format support, which is subject to the same restrictions as in Shogun's case. It is provided by an overloaded stream operator which accepts an \textit{std::ifstream} object of the C++ standard library. An example source code showing this mechanism is presented on listing \ref{dlib:csv}.

\cppcode{Rozdzial6/csv.cpp}{Code snippet illustrating read of CSV file - Dlib\cite{handsOnMachineLearning}.}{dlib:csv}

\section{Data processing and exploration}

\subsection{Normalizing}

The library provides data normalization via standardization, performed by the \textit{Dlib::vector\char`_normalizer} class. The main constraint of its use is the fact, that the whole training data cannot be placed in it at once, forcing the user to separate it into a number of vectors, and after the normalizing, placing them back together for further processing. An example was shown on listing \ref{dlib:normalizer}. 

\cppcode{Result/inc/dlib/normalizer.hpp}{Normalizer function - Dlib.}{dlib:normalizer}

\subsection{Dimensionality reduction}

\subsubsection{Principal component analysis}

The Principal component analysis method implementation in the Dlib library is offered via \textit{dlib::vector\char`_normalizer\char`_pca} class, which besides the dimensionality reduction also performs data normalization. It proves useful, as it guarantees that the reduction will be performed on correctly prepared observation values. Listing \ref{dlib:pca} shows a function that uses the aforementioned method.

\cppcode{Result/inc/dlib/pca.hpp}{Example of dimensionality reduction with PCA - Dlib.}{dlib:pca}

\subsubsection{Linear discriminant analysis}

The second of provided algorithms in Dlib is linear discriminant analysis. It is available as a \textit{dlib::compute\char`_lda\char`_transform}, which translates the matrix containing observations into a data transformation matrix. Due to the supervised nature of the algorithm, it is necessary to provide the values of labels, however the input data itself, in contrary to the PCA method, can be contained within a singular matrix object. Reduction is performed by multiplying the acquired matrix with the transposed vector containing an observation. Precise algorithm application was shown on listing \ref{dlib:lda}.

\cppcode{Result/inc/dlib/lda.hpp}{EXample of dimensionality reduction with LDA - Dlib.}{dlib:lda}

\subsubsection{Sammon mapping}

One algorithm that makes the Dlib library stand out among the others is an implementation of dimensionality reduction method via multidimensional scaling using a nonlinear algorithm - so called Sammon mapping\cite{sammon}. The whole algorithm is implemented via the \textit{dlib::sammon\char`_projection} class, and its use comes down to creating its instance. In order to use this method, the user needs to invoke the \textit{operator()}, providing the data vector and expected number of dimensions, receiving the transformed data. According to this, the exact use of the reduction function is limited to two lines of code. Precise example is shown by listing \ref{dlib:sammon}.

\cppcode{Result/inc/dlib/sammon.hpp}{Example of dimensionality reduction with Sammon mapping - Dlib.}{dlib:sammon}

\subsection{L2 regularization}

The Dlib library contains a trainer function which allows for using ridge regression, which performs L2 regularization, called \textit{rr\char`_trainer} for linear regression and \textit{krr\char`_trainer} for non-linear regression. Examples of use of each one of those methods were shown in the paragraphs describing linear and ridge kernel regression models.

\section{Machine learning models}

\subsection{Linear regression}

The realization or linear regression model within the Dlib library is indirect. It is performed by using a kernel ridge regression, passing a linear kernel. Subsequently the training process is carried out, storing the desired model into a functor. Listing 
\ref{dlib:linear} shows the details of aforementioned mechanism.

\cppcode{Result/inc/dlib/linear.hpp}{Example of linear regression - Dlib.}{dlib:linear}

\subsection{Support vector machine}

In order to perform a multiclass classification using support vector machine, the Dlib library provides a decision function class called \textit{dlib::one\char`_vs\char`_one\char`_decision\char`_function}. It stores the resulting model of support vector machine inside the \textit{one\char`_versus\char`_one} class, two which an SVM trainer is passed. Detailed example is shown on listing \ref{dlib:svm}.

\cppcode{Result/inc/dlib/svm.hpp}{Example of support vector machine - Dlib.}{dlib:svm}

\subsection{Neural network}

Neural network construction in case of Dlib begins with defining the network's architecture, using special template chain. The parameters create a network of nested layers, from the most inner one to the most outer one. Dlib provides the user with a separation of layer type from its activation functions, allowing user to precisely configure the networks characteristics. However, the syntax of created architecture is very clouded, which significantly complicates its analysis. After the architecture is created, the user needs to create and configure a series of solvers. The most common one offed by the library is stochastic gradient descent algorithm, implemented under the \textit{dlib::sgd} class. The third step is to configure a deep neural network trainer, provided by the \textit{dlib::dnn\char`_trainer} class, by setting parameters such as:

\begin{itemize}
	\item learning rate coefficient;
	\item learning rate change coefficient; 
	\item batch size;
	\item max epoch count.
\end{itemize}

During the creation of the trainer object, it accepts a reference to the network architecture and solver object. Training process is carried out by invoking the \textit{train()} method, and the resulting model is written in-place into the network architecture object. Listing \ref{dlib:neural} shows an example of building a neural network using this library.

\cppcode{Result/inc/dlib/neural.hpp}{Neural network example - Dlib.}{dlib:neural} 

\subsection{Kernel ridge regression}

Preparation of multiclass kernel ridge regression model in case of Dlib library is almost identical to the way of makign a multiclass support vector machine. The main difference is used trainer object, in this case of \textit{dlib::krr\char`_trainer} class. It is also possible to use the same kernel, as in support vector machine case. Listing \ref{dlib:krr} describes an example of the model use.

\cppcode{Result/inc/dlib/krr.hpp}{Kernel ridge regression example - Dlib.}{dlib:krr}

\section{Model analysis method}

\subsection{Pole pod wykresem krzywej charakterystycznej odbiornika}

The Dlib library contains implementation for a function that calculates ROC curve, however it requires a certain degree of data processing both before and after its use. In order to use it, data needs to be split into correctly and incorrectly classified. The result of this mechanism is a vector containing coordinates of points of the ROC curve, which allow the user to plot the curve. The area under the curve needs to be calculated manually, utilizing eg. one of the numerical integration methods. Listing \ref{dlib:eval} shows a function that calculates the values of model predictions, including calculation of the area under the ROC curve for classification task, by performing numerical integration via a trapezoid method.

\cppcode{Result/inc/dlib/eval.hpp}{Calculating area under the ROC curve - Dlib.}{dlib:eval}

\subsection{K-fold cross validation}

Carring out a K-fold cross validation using Dlib is a complex process. It is multiphase, beginning with defining own function calculating a metric that interests the user, based on the \textit{dlib::cross\char`_validate\char`_regression\char`_trainer()}. The part of acquiring target hyperparameter values is achieved via \textit{dlib::find\char`_min\char`_global()} function, which accepts an address of the optimizer function, containers storing the information about minimal and maximal allowed values for each hyperparameter and the number of allowed calls to the optimizer. In order to read the resulting values, the user needs to read subsequent fields of the \textit{x} member of the structure returned by \textit{find\char`_min\char`_global()}. The details were presented on an example from the handbook \cite{handsOnMachineLearning} on listing \ref{dlib:cross}.

\cppcode{Result/inc/dlib/cross.hpp}{Example of K-fold cross validation - Dlib.}{dlib:cross}

\section{Documentation and sources availability}

Dlib contains a set of examples in the form of source code snippets presenting various mechanisms, available on the main page of the project \cite{dlib:home}. It is also one of the main libraries described within the aforementioned handbook \cite{handsOnMachineLearning}. Unfortunately, majority of the community forums focus on using Dlib via its Python interface, which can make searching for specific problems much harder. It is worthy to mention, that besides machine learning functionalities, Dlib also offers other solutions, such as networking, which makes the navigation across the project site slightly more difficult due to the presence of potentially uninteresting features.